{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "import lasagne.layers as L\n",
    "import lasagne.regularization as R\n",
    "import lasagne.nonlinearities as O\n",
    "import lasagne.init as I\n",
    "\n",
    "fpX = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# READ TRAINING DATA #\n",
    "######################\n",
    "\n",
    "class LoadData(object):\n",
    "    \n",
    "    def __init__(self, path, width, height):\n",
    "        content = np.genfromtxt(path, delimiter=',', names=True, \n",
    "                                converters={'pixels': lambda a: np.fromstring(a, sep=' ', dtype='float32')},\n",
    "                                dtype=[('emotion', '<i8'), ('pixels', 'object'), ('Usage', '|S16')])\n",
    "        self.labs = content['emotion']\n",
    "        self.sort = content['Usage']\n",
    "        self.imgs = np.array([e for (i, e) in enumerate(content['pixels'])]).reshape((self.labs.shape[0], width, height))\n",
    "        \n",
    "    def getTrainingImgs(self):\n",
    "        return self.imgs[self.sort == 'Training']\n",
    "        \n",
    "    def getTrainingLabs(self):\n",
    "        return self.labs[self.sort == 'Training']\n",
    "        \n",
    "    def getValidateImgs(self):\n",
    "        return self.imgs[self.sort == 'PrivateTest']\n",
    "        \n",
    "    def getValidateLabs(self):\n",
    "        return self.labs[self.sort == 'PrivateTest']\n",
    "        \n",
    "        \n",
    "loader = LoadData(os.getcwd() + '/data/fer2013.csv', 48, 48)\n",
    "train_imgs = loader.getTrainingImgs()[:,np.newaxis,:,:]\n",
    "train_labs = loader.getTrainingLabs()\n",
    "valid_imgs = loader.getValidateImgs()[:,np.newaxis,:,:]\n",
    "valid_labs = loader.getValidateLabs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# HELPER FUNCTIONS #\n",
    "####################\n",
    "\n",
    "def embedding(x, c=10): \n",
    "    '''\n",
    "    Also known as one-hot embedding.\n",
    "    '''\n",
    "    y = np.zeros((len(x), c), dtype=fpX)\n",
    "    y[np.arange(len(x)), x] = 1\n",
    "    return y\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    '''\n",
    "    for a given 4d input image tensor and a 2d target tensor of one-hot embedding, \n",
    "    return a shuffled batch of input-target pair\n",
    "    '''\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "def print_lasagne_net(_net, skipnoparam=True):\n",
    "    '''\n",
    "    Print a summary of the layer and their parameter shapes\n",
    "    '''\n",
    "    layers = L.get_all_layers(_net)\n",
    "    for l in layers:\n",
    "        out = l.output_shape\n",
    "        par = l.get_params()\n",
    "        if skipnoparam and len(par)==0 and l.name==None:\n",
    "            continue\n",
    "        print \"Layer\\t: %s\\nName\\t: %s\\nType\\t: %s\" % (l, l.name, type(l))\n",
    "        print \"Shape\\t: %s\" % (out,)\n",
    "        if len(par)>0:\n",
    "            print \"Params\"\n",
    "            for p in par:\n",
    "                print \"        |-- {:<10}: {:}\".format(p.name, p.get_value().shape,)\n",
    "        print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# DEFINE CNN ARCH #\n",
    "###################\n",
    "\n",
    "npc = 1 # of channels in image\n",
    "npx = 48 # number of pixels width/height of images\n",
    "ny = 7 # of classes\n",
    "\n",
    "def model(__X):\n",
    "    '''\n",
    "    Convolutional Neural Network description\n",
    "    '''\n",
    "    _input = L.InputLayer((None, npc, npx, npx), input_var=__X, name='Data')\n",
    "    _convo1 = L.Conv2DLayer(_input, num_filters=64, filter_size=(ny,ny), stride=2, pad=3, name='Convolution 1')\n",
    "    _pool1 = L.MaxPool2DLayer(_convo1, pool_size=3, stride=2, pad=0, ignore_border=False, name='Pooling 1')\n",
    "    _lrn1 = L.LocalResponseNormalization2DLayer(_pool1, name='LRN 1')\n",
    "    _featEx1 = featEx(_lrn1)\n",
    "    _featEx2 = featEx(_featEx1)\n",
    "    _classifier = L.DenseLayer(_featEx2, ny)\n",
    "    return _classifier\n",
    "\n",
    "def featEx(__X):\n",
    "    '''\n",
    "    Parallel Feature Extraction Block creates two parallel paths of features\n",
    "    '''\n",
    "    _convoA = L.Conv2DLayer(__X, num_filters=96, filter_size=(1,1), stride=1, pad=0, name='FeatEX Convolution a')\n",
    "    _convoB = L.Conv2DLayer(_convoA, num_filters=208, filter_size=(3,3), stride=1, pad=1, name='FeatEX Convolution b')\n",
    "    _poolA = L.MaxPool2DLayer(__X, pool_size=3, stride=1, pad=1, name='FeatEx Pooling a')\n",
    "    _convoC = L.Conv2DLayer(_poolA, num_filters=64, filter_size=(1,1), stride=1, pad=0, name='FeatEX Convolution c')\n",
    "    _concat = L.ConcatLayer([_convoB, _convoC], name='FeatEx Concat')\n",
    "    _poolB = L.MaxPool2DLayer(_concat, pool_size=3, stride=2, pad=0, ignore_border=False, name='FeatEx Pooling b')\n",
    "    \n",
    "    return _poolB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer\t: <lasagne.layers.input.InputLayer object at 0x0000000009F261D0>\n",
      "Name\t: Data\n",
      "Type\t: <class 'lasagne.layers.input.InputLayer'>\n",
      "Shape\t: (None, 1, 48, 48)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.conv.Conv2DLayer object at 0x0000000009F26198>\n",
      "Name\t: Convolution 1\n",
      "Type\t: <class 'lasagne.layers.conv.Conv2DLayer'>\n",
      "Shape\t: (None, 64, 24, 24)\n",
      "Params\n",
      "        |-- Convolution 1.W: (64L, 1L, 7L, 7L)\n",
      "        |-- Convolution 1.b: (64L,)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.pool.MaxPool2DLayer object at 0x0000000033AF97F0>\n",
      "Name\t: Pooling 1\n",
      "Type\t: <class 'lasagne.layers.pool.MaxPool2DLayer'>\n",
      "Shape\t: (None, 64, 12, 12)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.normalization.LocalResponseNormalization2DLayer object at 0x0000000033AF9978>\n",
      "Name\t: LRN 1\n",
      "Type\t: <class 'lasagne.layers.normalization.LocalResponseNormalization2DLayer'>\n",
      "Shape\t: (None, 64, 12, 12)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.conv.Conv2DLayer object at 0x0000000033AF99B0>\n",
      "Name\t: FeatEX Convolution a\n",
      "Type\t: <class 'lasagne.layers.conv.Conv2DLayer'>\n",
      "Shape\t: (None, 96, 12, 12)\n",
      "Params\n",
      "        |-- FeatEX Convolution a.W: (96L, 64L, 1L, 1L)\n",
      "        |-- FeatEX Convolution a.b: (96L,)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.conv.Conv2DLayer object at 0x0000000033AF9B70>\n",
      "Name\t: FeatEX Convolution b\n",
      "Type\t: <class 'lasagne.layers.conv.Conv2DLayer'>\n",
      "Shape\t: (None, 208, 12, 12)\n",
      "Params\n",
      "        |-- FeatEX Convolution b.W: (208L, 96L, 3L, 3L)\n",
      "        |-- FeatEX Convolution b.b: (208L,)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.pool.MaxPool2DLayer object at 0x0000000033AF9EF0>\n",
      "Name\t: FeatEx Pooling a\n",
      "Type\t: <class 'lasagne.layers.pool.MaxPool2DLayer'>\n",
      "Shape\t: (None, 64, 12, 12)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.conv.Conv2DLayer object at 0x000000001E4850F0>\n",
      "Name\t: FeatEX Convolution c\n",
      "Type\t: <class 'lasagne.layers.conv.Conv2DLayer'>\n",
      "Shape\t: (None, 64, 12, 12)\n",
      "Params\n",
      "        |-- FeatEX Convolution c.W: (64L, 64L, 1L, 1L)\n",
      "        |-- FeatEX Convolution c.b: (64L,)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.merge.ConcatLayer object at 0x000000001E4852E8>\n",
      "Name\t: FeatEx Concat\n",
      "Type\t: <class 'lasagne.layers.merge.ConcatLayer'>\n",
      "Shape\t: (None, 272, 12, 12)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.pool.MaxPool2DLayer object at 0x000000001E4854A8>\n",
      "Name\t: FeatEx Pooling b\n",
      "Type\t: <class 'lasagne.layers.pool.MaxPool2DLayer'>\n",
      "Shape\t: (None, 272, 6, 6)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.conv.Conv2DLayer object at 0x000000001E4854E0>\n",
      "Name\t: FeatEX Convolution a\n",
      "Type\t: <class 'lasagne.layers.conv.Conv2DLayer'>\n",
      "Shape\t: (None, 96, 6, 6)\n",
      "Params\n",
      "        |-- FeatEX Convolution a.W: (96L, 272L, 1L, 1L)\n",
      "        |-- FeatEX Convolution a.b: (96L,)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.conv.Conv2DLayer object at 0x000000001E4856D8>\n",
      "Name\t: FeatEX Convolution b\n",
      "Type\t: <class 'lasagne.layers.conv.Conv2DLayer'>\n",
      "Shape\t: (None, 208, 6, 6)\n",
      "Params\n",
      "        |-- FeatEX Convolution b.W: (208L, 96L, 3L, 3L)\n",
      "        |-- FeatEX Convolution b.b: (208L,)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.pool.MaxPool2DLayer object at 0x000000001E485A58>\n",
      "Name\t: FeatEx Pooling a\n",
      "Type\t: <class 'lasagne.layers.pool.MaxPool2DLayer'>\n",
      "Shape\t: (None, 272, 6, 6)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.conv.Conv2DLayer object at 0x000000001E485C18>\n",
      "Name\t: FeatEX Convolution c\n",
      "Type\t: <class 'lasagne.layers.conv.Conv2DLayer'>\n",
      "Shape\t: (None, 64, 6, 6)\n",
      "Params\n",
      "        |-- FeatEX Convolution c.W: (64L, 272L, 1L, 1L)\n",
      "        |-- FeatEX Convolution c.b: (64L,)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.merge.ConcatLayer object at 0x000000001E485E10>\n",
      "Name\t: FeatEx Concat\n",
      "Type\t: <class 'lasagne.layers.merge.ConcatLayer'>\n",
      "Shape\t: (None, 272, 6, 6)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.pool.MaxPool2DLayer object at 0x000000001E485FD0>\n",
      "Name\t: FeatEx Pooling b\n",
      "Type\t: <class 'lasagne.layers.pool.MaxPool2DLayer'>\n",
      "Shape\t: (None, 272, 3, 3)\n",
      "\n",
      "\n",
      "Layer\t: <lasagne.layers.dense.DenseLayer object at 0x000000001E48D048>\n",
      "Name\t: None\n",
      "Type\t: <class 'lasagne.layers.dense.DenseLayer'>\n",
      "Shape\t: (None, 7)\n",
      "Params\n",
      "        |-- W         : (2448L, 7L)\n",
      "        |-- b         : (7L,)\n",
      "\n",
      "\n",
      "[Convolution 1.W, Convolution 1.b, FeatEX Convolution a.W, FeatEX Convolution a.b, FeatEX Convolution b.W, FeatEX Convolution b.b, FeatEX Convolution c.W, FeatEX Convolution c.b, FeatEX Convolution a.W, FeatEX Convolution a.b, FeatEX Convolution b.W, FeatEX Convolution b.b, FeatEX Convolution c.W, FeatEX Convolution c.b, W, b]\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "## THEANO COMPILE ##\n",
    "####################\n",
    "\n",
    "_X = T.tensor4() # a theano variable representing the input data\n",
    "_Y = T.matrix() # a theano variable representing the class label\n",
    "\n",
    "_cls = model(_X)\n",
    "cls_params = L.get_all_params(_cls, trainable=True) # all trainable Theano shared params\n",
    "\n",
    "print_lasagne_net(_cls, skipnoparam=False)\n",
    "\n",
    "print cls_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(__y):\n",
    "    '''The loss function used to train the network -- tells what is good and what is bad'''\n",
    "    return O.softmax(__y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cost must be a scalar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8f67ef64157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0m_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cls_val_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcls_updates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cls_trn_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_lr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[1;31m#cls_updates = lasagne.updates.apply_momentum(cls_updates, cls_params, momentum=0.9)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Joey\\Anaconda3\\envs\\py27\\lib\\site-packages\\lasagne\\updates.pyc\u001b[0m in \u001b[0;36msgd\u001b[0;34m(loss_or_grads, params, learning_rate)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mto\u001b[0m \u001b[0mits\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0mexpression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_or_compute_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_or_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Joey\\Anaconda3\\envs\\py27\\lib\\site-packages\\lasagne\\updates.pyc\u001b[0m in \u001b[0;36mget_or_compute_grads\u001b[0;34m(loss_or_grads, params)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss_or_grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_or_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Joey\\Anaconda3\\envs\\py27\\lib\\site-packages\\theano\\gradient.pyc\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(cost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected, null_gradients)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cost must be a scalar.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cost must be a scalar."
     ]
    }
   ],
   "source": [
    "_lr = theano.shared(fpX(0))\n",
    "_l2 = theano.shared(fpX(0))\n",
    "\n",
    "_cls_reg = _l2 * R.regularize_layer_params(_cls, R.l2) # regularization loss\n",
    "_cls_trn_pred = L.get_output(_cls, deterministic=False) # training prediction\n",
    "_cls_trn_loss = loss(_cls_trn_pred) + _cls_reg # total training loss\n",
    "_cls_trn_acc = T.mean(T.eq(T.argmax(_cls_trn_pred, axis=1), T.argmax(_Y, axis=1)), dtype=theano.config.floatX) # validation accuracies\n",
    "\n",
    "_cls_val_pred = L.get_output(_cls, deterministic=True) #validation prediction\n",
    "_cls_val_loss = loss(_cls_val_pred) + _cls_reg # total validation loss\n",
    "_cls_val_acc = T.mean(T.eq(T.argmax(_cls_val_pred, axis=1), T.argmax(_Y, axis=1)), dtype=theano.config.floatX) # validation accuracies\n",
    "\n",
    "_class = T.argmax(_cls_val_pred, axis=1)\n",
    "\n",
    "cls_updates = lasagne.updates.sgd(_cls_trn_loss, cls_params, learning_rate=_lr) \n",
    "#cls_updates = lasagne.updates.apply_momentum(cls_updates, cls_params, momentum=0.9)\n",
    "\n",
    "print 'COMPILING'\n",
    "t = time.time()\n",
    "cls_trn_fn = theano.function([_X, _Y], [_cls_trn_loss, _cls_trn_acc], updates=cls_updates)\n",
    "cls_val_fn = theano.function([_X, _Y], [_cls_val_loss, _cls_val_acc])\n",
    "cls_pred_fn = theano.function([_X], _class)\n",
    "print '%.2f seconds to compile theano functions'%(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 1.   # initial learning rate for sgd\n",
    "l2 = 0.    # l2 weight decay\n",
    "niter = 5       # # of iter at starting learning rate\n",
    "perc_decay = 5.0 # # of iter to linearly decay learning rate to zero\n",
    "num_epochs = 5\n",
    "batch_size = 1000\n",
    "max_trn_size = 6000\n",
    "\n",
    "_lr.set_value(fpX(lr))\n",
    "_l2.set_value(fpX(l2))\n",
    "\n",
    "trn_emb_label = embedding(train_labs, ny)\n",
    "val_emb_label = embedding(valid_labs, ny)\n",
    "\n",
    "trn_hist = []\n",
    "val_hist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    trn_err = 0\n",
    "    trn_acc = 0\n",
    "    trn_batches = 0\n",
    "    start_time = time.time()\n",
    "    for xb, yb in tqdm(iterate_minibatches(train_imgs[:max_trn_size], trn_emb_label[:max_trn_size], batch_size, shuffle=False)):\n",
    "        _, _ = cls_trn_fn(xb, yb)\n",
    "    \n",
    "    for xb, yb in iterate_minibatches(train_imgs[:max_trn_size], trn_emb_label[:max_trn_size], batch_size, shuffle=False):\n",
    "        err, acc = cls_val_fn(xb, yb)\n",
    "        trn_err += err\n",
    "        trn_acc += acc\n",
    "        trn_batches += 1\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for xb, yb in iterate_minibatches(valid_imgs, val_emb_label, batch_size, shuffle=False):\n",
    "        err, acc = cls_val_fn(xb, yb)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    trn_hist += [trn_acc / trn_batches,]\n",
    "    val_hist += [val_acc / val_batches,]\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"\\n  Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:       {:.6f}\".format(trn_err / trn_batches))\n",
    "    print(\"  training accuracy:   {:.2f} %\".format(trn_acc / trn_batches * 100))\n",
    "    print(\"  validation loss:     {:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy: {:.2f} %\".format(val_acc / val_batches * 100))\n",
    "    \n",
    "    if epoch > niter:\n",
    "        _lr.set_value(fpX(_lr.get_value() * (1.0 - perc_decay / 100.0)))     \n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5rZYbmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x34617048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_imgs[11,:], cmap='gray')\n",
    "print train_labs[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sources\n",
    "\n",
    "* [Kaggle dataset](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/discussion)\n",
    "* [Stanford CS231 CNN](http://cs231n.github.io/convolutional-networks/)\n",
    "* [DeXpression: Deep CNN for Expression Recognition](https://arxiv.org/pdf/1509.05371.pdf)\n",
    "* [What is LRN in CNNs](https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/)\n",
    "* [ImageNet Classification with Deep CNNs](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
